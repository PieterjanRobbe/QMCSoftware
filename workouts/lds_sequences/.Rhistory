cooksd <- cooks.distance(mod)
plot(cooksd, pch="*", cex=2, main="Outliers")  # plot cook's distance
mod <- lm(salary ~ ., data=df_final)
cooksd <- cooks.distance(mod)
plot(cooksd, main="Outliers")  # plot cook's distance
mod <- lm(salary ~ ., data=df_final)
cooksd <- cooks.distance(mod)
plot(cooksd)#, pch="*", cex=2, main="Outliers")  # plot cook's distance
p_vars_subset <- c('name','salary',p_vars_final)
get_salary_formula <- function(x_vars){
return(as.formula(sprintf('salary ~ `%s`',paste(x_vars,collapse='` + `'))))}
library(rms)
p_x_vars <- names(p_train_df)[!(names(p_train_df))%in%c('salary','name','2P','2PA','PTS','TRB')]
library(plumber)
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(qrng)
?sobol
sobol(8,2,randomize="none",skip=0)
sobol(6,2,randomize="none",skip=0)
sobol(6,2,randomize="none",skip=2)
sobol(6,2,randomize="digital.shift",skip=2,seed=7)
sobol(6,2,randomize="Owen",skip=2,seed=7)
sobol(2**10,2,randomize="digital.shift",skip=0,seed=7)
x <- sobol(2**10,2,randomize="digital.shift",skip=0,seed=7)
dim(x)
plot(x)
scatter(x)
plot(x[,0],x[,1])
dim(x)
?plot
dim(x[,1])
x[,1]
plot(x[,1],x[,2])
plot(c(1,2,3),c(4,5,6))
base::plot(c(1,2,3),c(4,5,6))
base::plot(x=c(1,2,3),y=c(4,5,6))
plot(x=c(1,2,3),y=c(4,5,6))
l = list(x=x[,1],y=x[,2])
l
dim(l$x)
str(l$x)
plot(l$x,l$y)
plot(l$x)
library(ggplot2)
ggplot(l, aes(x=x, y=y)) + geom_point()
ld = as.data.frame(l)
ld
names(ld)
ggplot(ld, aes(x=x, y=y)) + geom_point()
plot(as.data.frame(sobol(2**11,2)))
names(as.data.frame(sobol(2**11,2)))
ggplot(sobol(n=2^11,d=2), aes(x=V1, y=V2)) + geom_point()
ggplot(as.data.frame(sobol(n=2^11,d=2)), aes(x=V1, y=V2)) + geom_point()
sobol(2^20,2)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?",
"Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&",
"TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&",
"OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&",
"X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&",
"BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
df_c.train[df_c.train$name=='lebron james'&df_c.train$year=='2016',]
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?",
"Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&",
"TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&",
"OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&",
"X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&",
"BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
#df_c.train[df_c.train$name=='lebron james'&df_c.train$year=='2016',]
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
#df_c.train[df_c.train$name=='lebron james'&df_c.train$year=='2016',]
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
df_p.all <- read.csv('../data/pooled/primary.csv')
df_p.all$year <- as.factor(df_p.all$year)
str(df_p.all)
head(df_p.all)
df_c.all <- read.csv('../data/pooled/complete.csv')
df_c.all$year <- as.factor(df_c.all$year)
str(df_c.all)
head(df_c.all)
library(caret)
set.seed(7)
# primary dataset
train_rows.p <- createDataPartition(y=df_p.all[,'salary'], list=FALSE, p=.8)
df_p.train <- df_p.all[train_rows.p,]
df_p.test <- df_p.all[-train_rows.p,]
nrow(df_p.all)
nrow(df_p.train)
nrow(df_p.test)
# complete dataset
train_rows.c <- createDataPartition(y=df_c.all[,'salary'], list=FALSE, p=.8)
df_c.train <- df_c.all[train_rows.c,]
df_c.test <- df_c.all[-train_rows.c,]
nrow(df_c.all)
nrow(df_c.train)
nrow(df_c.test)
df_p_vs.train = read.csv('../data/train_test/primary/train_selected.csv')
df_p_vs.train$year <- as.factor(df_p_vs.train$year)
df_p_vs.test = read.csv('../data/train_test/primary/test_selected.csv')
df_p_vs.test$year <- as.factor(df_p_vs.test$year)
df_c_vs.train = read.csv('../data/train_test/complete/train_selected.csv')
df_c_vs.test = read.csv('../data/train_test/complete/test_selected.csv')
r_squared <- function(y,yHat){1-sum((y-yHat)^2)/sum((y-mean(y))^2)}
mse <- function(y,yHat){mean((y-yHat)^2)}
model_results <- function(model,dataset,y,yHat){
r2_test <- r_squared(y,yHat)
mse_test <- mse(y,yHat)
cat(sprintf('Model: %-25s Dataset: %-15s R^2 Test: %-10.3f MSE: %-10.3e\n',model,dataset,r2_test,mse_test))}
# modeling function
slr_modeling <- function(dataset,df_train,df_test){
model <- 'SLR'
x_vars <- names(df_train)[!(names(df_train)%in%c('name','salary','X2P','X2PA','TRB','PTS'))]
f <- as.formula(sprintf('salary ~ `%s`',paste(x_vars,collapse='` + `')))
slr_model <- lm(f,data=df_train)
yhat <- predict(slr_model,df_test)
model_results(model,dataset,df_test[['salary']],yhat)
return(slr_model)}
# train/test Simple Linear Regression models
names(df_p.train)
ignore <- slr_modeling('primary',df_p.train,df_p.test)
ignore <- slr_modeling('complete',df_c.train,df_c.test)
names(df_p_vs.train)
ignore <- slr_modeling('primary VS',df_p_vs.train,df_p_vs.test) # primary variable subset
ignore <- slr_modeling('complete VS',df_c_vs.train,df_c_vs.test) # complete variable subset
# modeling function
slr_modeling <- function(dataset,df_train,df_test){
model <- 'SLR'
x_vars <- names(df_train)[!(names(df_train)%in%c('name','salary','X2P','X2PA','TRB','PTS'))]
f <- as.formula(sprintf('salary ~ `%s`',paste(x_vars,collapse='` + `')))
slr_model <- lm(f,data=df_train)
yhat <- predict(slr_model,df_test)
model_results(model,dataset,df_test[['salary']],yhat)
return(slr_model)}
# train/test Simple Linear Regression models
names(df_p.train)
ignore <- slr_modeling('primary',df_p.train,df_p.test)
slr_modeling('complete',df_c.train,df_c.test)
names(df_p_vs.train)
ignore <- slr_modeling('primary VS',df_p_vs.train,df_p_vs.test) # primary variable subset
ignore <- slr_modeling('complete VS',df_c_vs.train,df_c_vs.test) # complete variable subset
# modeling function
slr_modeling <- function(dataset,df_train,df_test){
model <- 'SLR'
x_vars <- names(df_train)[!(names(df_train)%in%c('name','salary','X2P','X2PA','TRB','PTS'))]
f <- as.formula(sprintf('salary ~ `%s`',paste(x_vars,collapse='` + `')))
slr_model <- lm(f,data=df_train)
yhat <- predict(slr_model,df_test)
model_results(model,dataset,df_test[['salary']],yhat)
return(slr_model)}
# train/test Simple Linear Regression models
names(df_p.train)
ignore <- slr_modeling('primary',df_p.train,df_p.test)
ignore <- slr_modeling('complete',df_c.train,df_c.test)
summary(ignore)
names(df_p_vs.train)
ignore <- slr_modeling('primary VS',df_p_vs.train,df_p_vs.test) # primary variable subset
ignore <- slr_modeling('complete VS',df_c_vs.train,df_c_vs.test) # complete variable subset
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
sqrt(1.947e+13)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
df_c.train[df_c.train$name=='lebron james'&df_c.train$year=='2016',]
df_p.all <- read.csv('../data/pooled/primary.csv')
df_p.all$year <- as.factor(df_p.all$year)
str(df_p.all)
head(df_p.all)
df_c.all <- read.csv('../data/pooled/complete.csv')
df_c.all$year <- as.factor(df_c.all$year)
str(df_c.all)
head(df_c.all)
library(caret)
set.seed(7)
# primary dataset
train_rows.p <- createDataPartition(y=df_p.all[,'salary'], list=FALSE, p=.8)
df_p.train <- df_p.all[train_rows.p,]
df_p.test <- df_p.all[-train_rows.p,]
nrow(df_p.all)
nrow(df_p.train)
nrow(df_p.test)
# complete dataset
train_rows.c <- createDataPartition(y=df_c.all[,'salary'], list=FALSE, p=.8)
df_c.train <- df_c.all[train_rows.c,]
df_c.test <- df_c.all[-train_rows.c,]
nrow(df_c.all)
nrow(df_c.train)
nrow(df_c.test)
df_p_vs.train = read.csv('../data/train_test/primary/train_selected.csv')
df_p_vs.train$year <- as.factor(df_p_vs.train$year)
df_p_vs.test = read.csv('../data/train_test/primary/test_selected.csv')
df_p_vs.test$year <- as.factor(df_p_vs.test$year)
df_c_vs.train = read.csv('../data/train_test/complete/train_selected.csv')
df_c_vs.test = read.csv('../data/train_test/complete/test_selected.csv')
r_squared <- function(y,yHat){1-sum((y-yHat)^2)/sum((y-mean(y))^2)}
mse <- function(y,yHat){mean((y-yHat)^2)}
model_results <- function(model,dataset,y,yHat){
r2_test <- r_squared(y,yHat)
mse_test <- mse(y,yHat)
cat(sprintf('Model: %-25s Dataset: %-15s R^2 Test: %-10.3f MSE: %-10.3e\n',model,dataset,r2_test,mse_test))}
# modeling function
slr_modeling <- function(dataset,df_train,df_test){
model <- 'SLR'
x_vars <- names(df_train)[!(names(df_train)%in%c('name','salary','X2P','X2PA','TRB','PTS'))]
f <- as.formula(sprintf('salary ~ `%s`',paste(x_vars,collapse='` + `')))
slr_model <- lm(f,data=df_train)
yhat <- predict(slr_model,df_test)
model_results(model,dataset,df_test[['salary']],yhat)
return(slr_model)}
# train/test Simple Linear Regression models
names(df_p.train)
ignore <- slr_modeling('primary',df_p.train,df_p.test)
ignore <- slr_modeling('complete',df_c.train,df_c.test)
summary(ignore)
names(df_p_vs.train)
ignore <- slr_modeling('primary VS',df_p_vs.train,df_p_vs.test) # primary variable subset
ignore <- slr_modeling('complete VS',df_c_vs.train,df_c_vs.test) # complete variable subset
library(ggplot2)
r2_data <- as.data.frame(list(
dataset = c('Primary All','Complete All','Primary Subset','Complete Subset'),
r2 =      c(.464,         .469,            .519,          .526)))
ggplot(data=r2_data, aes(x=dataset, y=r2)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal()
ggsave("../figures/slr_r2_bar.png");
library(ggplot2)
rmse_data <- as.data.frame(list(
dataset = c('Primary All','Complete All','Primary Subset','Complete Subset'),
rmse_millions =      c(5.17,         5.07,          4.89,           4.85)))
ggplot(data=rmse_data, aes(x=dataset, y=rmse_millions)) +
geom_bar(stat="identity", fill="lightgreen") +
theme_minimal()
ggsave("../figures/slr_rmse_bar.png");
library(glmnet)
# modeling function
lre_modeling <- function(dataset,x_train,y_train,x_test,y_test,alphas,mkplot){
# fit models
for (i in alphas){
set.seed(7) # seed for reproducibility
model_name <- sprintf('fit_alpha_%.2f',i)
assign(model_name, cv.glmnet(x_train, y_train, type.measure="mse",alpha=i,family="gaussian"))
model <- get(model_name)
yhat <- predict(model,s=model$lambda.min,newx=x_test)
model_results(model_name,dataset,y_test,yhat)
# plot
if(mkplot){
path = sprintf("../figures/elasticnet_models/alpha_%.2f.%s.png",i,dataset)
png(file=path)
par(mfrow=c(2,1))
glmnet_model <- glmnet(x_train, y_train, family="gaussian",alpha=i)
plot(glmnet_model)
title(sprintf('Elasticnet Model, %s dataset, alpha = %.2f',dataset,i),line=3)
plot(model,xvar='lambda')
dev.off()}}
return(model)} # return final model created
# extract train/test datasets of only numeric variables as required by glmnet models
#    primary dataset
numeric_vars.p <- names(Filter(is.numeric,df_p.train))
numeric_x_vars.p <- numeric_vars.p[!(numeric_vars.p%in%c('salary'))]
x_train.p <- data.matrix(df_p.train[,numeric_x_vars.p])
y_train.p <- df_p.train[['salary']]
x_test.p <- data.matrix(df_p.test[,numeric_x_vars.p])
y_test.p <- df_p.test[['salary']]
#    complete dataset
numeric_vars.c <- names(Filter(is.numeric,df_c.train))
numeric_x_vars.c <- numeric_vars.c[!(numeric_vars.c%in%c('salary'))]
x_train.c <- data.matrix(df_c.train[,numeric_x_vars.c])
y_train.c <- df_c.train[['salary']]
x_test.c <- data.matrix(df_c.test[,numeric_x_vars.c])
y_test.c <- df_c.test[['salary']]
# train/test Simple Linear Regression models
mkplots <- FALSE # change to TRUE if you want to generate plots
ignore <- lre_modeling('primary',x_train.p,y_train.p,x_test.p,y_test.p,seq(0,1,by=.05),mkplots)
ignore <- lre_modeling('complete',x_train.c,y_train.c,x_test.c,y_test.c,seq(0,1,by=.05),mkplots)
numeric_x_vars.c
optimal_model <- lre_modeling('complete',x_train.c,y_train.c,x_test.c,y_test.c,c(0),mkplots)
optimal_model$lambda.min
saveRDS(optimal_model,file='../data/optimal_model/elasticnet/model.rds')
df_c.train[df_c.train$name=='lebron james'&df_c.train$year=='2016',]
df_c.all.copy <- df_c.all
x <- data.matrix(df_c.all[,numeric_x_vars.c])
df_c.all.copy$salary_hat_elasticnet <- as.vector(predict(optimal_model,s=optimal_model$lambda.min,newx=x))
df_c.all.copy <- df_c.all.copy[,c('name','year','salary','salary_hat_elasticnet')]
names(df_c.all.copy) <- c('name','year','salary','salary_hat')
head(df_c.all.copy)
write.csv(df_c.all.copy,'../data/predictions/elasticnet.csv',row.names=F)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
library(plumber)
paste(
"curl -X POST 'http://localhost:8000/predict_salary?",
"Age=31&G=76&GS=76&MP=2709&PER=27.5&TS.=.588&X3PAr=0.199&",
"FTr=0.347&ORB.=4.7&DRB.=18.8&TRB.=11.8&AST.=36.0&STL.=2.0&",
"BLK.=1.5&TOV.=13.2&USG.=31.4&OWS=9.6&DWS=4&WS=13.6&",
"WS.48=0.242&OBPM=6.9&DBPM=2.3&BPM=9.1&VORP=7.6&FG=737&",
"FGA=1416&FG.=0.520&X3P=87&X3PA=282&X3P.=0.309&X2P=650&",
"X2PA=1134&X2P.=0.573&eFG.=0.551&FT=359&FTA=491&FT.=0.731&",
"ORB=111&DRB=454&TRB=565&AST=514&STL=104&BLK=49&TOV=249&",
"PF=143&PTS=1920&out=94&ovr=99&ins=89&pla=91&ath=92&def=91&reb=91'",
sep='')
r <- plumb("./deploy_optimal_model.R")
r$run(port=8000)
?sample
sample(0:2,prob=c(.1,.1,.1))
sample(0:2,prob=c(.1,.1,.1))
sample(0:2,prob=c(.1,.1,.1))
sample(0:2,prob=c(.1,.1,.1))
sample(0:2,prob=c(.1,.1,.1))
sample(0:2,n=1,prob=c(.1,.1,.1))
sample(x=0:2,n=1,prob=c(.1,.1,.1))
sample(n=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
sample(0:2,size=1,prob=c(.1,.1,.1))
hist(sample(0:2,size=1000,prob=c(.1,.1,.1)))
hist(sample(0:2,size=1000,prob=c(.1,.1,.1),replace=T))
hist(sample(0:2,size=10000,prob=c(.1,.1,.1),replace=T))
set.seed(2020)
theta <- runif(1)
z <- rbinom(n=1,size=9,prob=theta)
y <- rpois(n=14, lambda=z)
set.seed(2020)
theta <- runif(1)
z <- rbinom(n=1,size=9,prob=theta)
y <- rpois(n=14, lambda=z)
j <- 0:4
j
?choose
choose(5,3)
choose(3,3)
choose(5,1:5)
choose(5,0:5)
?read.excel
?read
?read.csv
?excel
j <- 0:9
z_post_marginal <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )
z_post_marginal
?sample
set.seed(2020)
theta <- runif(1)
z <- rbinom(n=1,size=9,prob=theta)
y <- rpois(n=14, lambda=z)
z_post_marginal <- function(theta){
j <- 0:9
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=1000,replace=T,prob=zpm),main='Samples from z marginal posterior')
?hist
j <- 0:9
z_post_marginal <- function(theta){
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=1000,replace=T,prob=zpm),breaks=j,main='Samples from z marginal posterior')
j <- 0:9
z_post_marginal <- function(theta){
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=1000,replace=T,prob=zpm),breaks=j,main='Samples from z marginal posterior',xlab='z')
j <- 0:9
z_post_marginal <- function(theta){
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=1000,replace=T,prob=zpm),breaks=j,main='Samples from z marginal posterior',xlab='z',probability=T)
j <- 0:9
z_post_marginal <- function(theta){
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=10000,replace=T,prob=zpm),breaks=j,main='Samples from z marginal posterior',xlab='z',probability=T)
j <- 0:9
z_post_marginal <- function(theta){
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=1000,replace=T,prob=zpm),breaks=j,main='Samples From Marginal Posterior for z',xlab='z',probability=T)
n_sim <- 1000
j <- 0:9
z_post_marginal <- function(theta){
zpm <- exp( sum(y)*log(j) - 14*j + log(choose(9,j)) + j*log(theta) + (9-j)*log(1-theta) )}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=n_sim,replace=T,prob=zpm),breaks=j,main='Samples From Marginal Posterior for z',xlab='z',probability=T)
n_sim <- 1000
j <- 0:9
z_post_marginal <- function(theta_){
zpm <- exp( log(choose(9,j)) + j*log(theta_) + (9-j)*log(1-theta_) + sum(y)*log(j) - 14*j )
zpm <- zpm/sum(zpm)
return(zpm)}
zpm <- z_post_marginal(theta)
hist(sample(0:9,size=n_sim,replace=T,prob=zpm),
breaks=j,main='Samples From Marginal Posterior for z',xlab='z',probability=T)
glm(y~x-1,family=binomial('logit'))
set.seed(2020)
n <- 100
x <- cbind(1,rnorm(n))
true.beta <- c(0,0.5)
true.p <- exp(x%*%true.beta)/(1+exp(x%*%true.beta))
y <- rbinom(n,1,true.p)
glm(y~x-1,family=binomial('logit'))
summary(glm(y~x-1,family=binomial('logit')))
summary(glm(y~x-1,family=binomial('logit')))$coefficients
library(qrng)
sobol(4,2,randomize='none',seed=7,skip=4)
library(qrng)
n <- 2^11
d <- 2
korobov_pts <- korobov(n,d,generator=c(4),randomize='shift')
plot(korobov_pts,cex=.2)
ghalton_pts <- ghalton(n,d,method='generalized')
plot(ghalton_pts,cex=.2)
sobol_pts <- sobol(n,d,randomize='digital.shift',seed=7,skip=0)
plot(sobol_pts,cex=.2)
sobol(4,2,randomize='digital.shift',seed=7,skip=4)
?sobol
sobol(4,2,randomize='digital.shift',seed=7,skip=0)
sobol(4,2,randomize='none',seed=7,skip=0)
sobol(4,2,randomize='Owen',seed=7,skip=0)
korobov_pts <- korobov(n,d,generator=c(1,2),randomize='shift')
plot(korobov_pts,cex=.2)
korobov_pts <- korobov(n,d,generator=c(1,4),randomize='shift')
plot(korobov_pts,cex=.2)
korobov_pts <- korobov(n,d,generator=c(1,2),randomize='shift')
plot(korobov_pts,cex=.2)
korobov_pts <- korobov(n,d,generator=c(2,4),randomize='shift')
plot(korobov_pts,cex=.2)
korobov_pts <- korobov(n,d,generator=c(0,4),randomize='shift')
korobov_pts <- korobov(n,d,generator=c(1,4),randomize='shift')
plot(korobov_pts,cex=.2)
sobol_pts <- sobol(n,d,randomize='digital.shift',seed=7,skip=0)
plot(sobol_pts,cex=.2)
sobol_pts <- sobol(n,d,randomize='digital.shift',seed=7,skip=0)
plot(sobol_pts,cex=.2)
n
2^11
library(qrng)
n <- 2^12
d <- 2
korobov_pts <- korobov(n,d,generator=c(1,4),randomize='shift')
plot(korobov_pts,cex=.2)
ghalton_pts <- ghalton(n,d,method='generalized')
plot(ghalton_pts,cex=.2)
sobol_pts <- sobol(n,d,randomize='digital.shift',seed=7,skip=0)
plot(sobol_pts,cex=.2)
n
library(qrng)
citation(qrng)
citation('qrng')
library(qrng)
citation("qrng")
setwd("~/Desktop/GitHub/QMCSoftware/workouts/lds_sequences")
source('~/Desktop/GitHub/QMCSoftware/workouts/lds_sequences/r_sequences.r', echo=TRUE)
source('~/Desktop/GitHub/QMCSoftware/workouts/lds_sequences/r_sequences.r', echo=TRUE)
